{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "\n",
    "In this exercise, I practice using Apache Spark by 1) finding all \"reciprocal\" relationships in a sample of emails uncovered during the investigation of Enron and 2) analyzing NYC high school SAT performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enron\n",
    "\n",
    "**Reciprocal v Directed:**\n",
    "\n",
    "If A emails B and B emails A, then A and B is *reciprocal*.\n",
    "\n",
    "If A emails B but B doesn’t email A, then A and B is *directed*.\n",
    "\n",
    "**Dataset:** A subset of the open [Enron Email Dataset](https://www.cs.cmu.edu/~./enron/ \"Enron Email Dataset\"), which contains approximately 10,000 simplified email headers from the Enron Corporation. The file contains 3 columns *Date*, *From*, and *To*. Their description is as follows:\n",
    "\n",
    "|Column name|Description|\n",
    "|--|--|\n",
    "|Date |The date and time of the email, in the format YYYY-MM-DD hh-mm-ss, <br />e.g. \"1998-10-30 07:43:00\" |\n",
    "|From |The sender email address, <br />e.g. \"mark.taylor@enron.com\" |\n",
    "|To | A list of recipients' email addresses separated by semicolons ';', <br />e.g. \"jennifer.fraser@enron.com;jeffrey.hodge@enron.com\" |\n",
    "\n",
    "Note that, we only care about users employed by Enron, or only relationships having email addresses that end with *'@enron.com'*. Though the dataset only contains email addresses, not actual names, we're assuming that the email aliases were created based on their name. For example:\n",
    "\n",
    "|Email Address|Converted Name|\n",
    "|--|--|\n",
    "|mark.taylor@enron.com|Mark Taylor|\n",
    "|alan.aronowitz@enron.com|Alan Aronowitz|\n",
    "|marc.r.cutler@enron.com|Marc R Cutler|\n",
    "|hugh@enron.com|Hugh|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://samuels-air-4.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for original data\n",
    "ENRON = 'data/enron_mails_small.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD with the target data\n",
    "enron = sc.textFile(ENRON, use_unicode=True).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark Taylor', 'Shari Stack'),\n",
       " ('Mark Taylor', 'Yao Apasu'),\n",
       " ('Mark Taylor', 'Paul Simons'),\n",
       " ('Mark Taylor', 'Justin Boyd'),\n",
       " ('Mark Taylor', 'Tana Jones')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract the froms and tos from the Enron email data set, check to make sure '@enron.com' is in the address, take only\n",
    "the names, and capitalize them (k2 - v2: from - to).\n",
    "\"\"\"\n",
    "def extractNames(partitionId, rows):\n",
    "    # Skip the first row\n",
    "    if partitionId==0:\n",
    "        next(rows)\n",
    "    import csv\n",
    "    # Read in the data\n",
    "    reader = csv.reader(rows)\n",
    "    for fields in reader:\n",
    "        # Split the recipient email addresses\n",
    "        for to in fields[2].strip().split(';'):\n",
    "            # Check to make sure '@enron.com' is in the address\n",
    "            if '@enron.com' in to and '@enron.com' in fields[1]:\n",
    "                # Yield the froms and every to for each from\n",
    "                yield (fields[1].split('@')[0].replace('.',' ').title(), \\\n",
    "                       to.split('@')[0].replace('.',' ').title())\n",
    "    \n",
    "enronNames = enron.mapPartitionsWithIndex(extractNames)\n",
    "enronNames.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Count all the reciprocal relationships\n",
    "\n",
    "Steps: \n",
    "1) Get all the from-to pairs, sort them and give each pair a 1 (k3 - v3: from-to - 1)\n",
    "2) Reduce all the k3 - v3 pairs by the keys (k4 - v4: from-to - sum of v3)\n",
    "3) Only take any k4 - v4 pairs where v4 > 1 (k5 - v5: from-to - sum of v4>1)\n",
    "4) Format the result using map (k6 - v6: 'reciprocal' - name1 : name2)\n",
    "5) Count\n",
    "\"\"\"\n",
    "enronNames.distinct() \\\n",
    "    .map(lambda x: (tuple(sorted(x)), 1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .filter(lambda x: x[1] > 1) \\\n",
    "    .map(lambda x: ('reciprocal', str(x[0][0]) + ' : ' + str(x[0][1]))) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reciprocal', 'Brenda Whitehead : Elizabeth Sager'),\n",
       " ('reciprocal', 'Carol Clair : Debra Perlingiere'),\n",
       " ('reciprocal', 'Carol Clair : Mark Taylor'),\n",
       " ('reciprocal', 'Carol Clair : Richard Sanders'),\n",
       " ('reciprocal', 'Carol Clair : Sara Shackleton'),\n",
       " ('reciprocal', 'Carol Clair : Tana Jones'),\n",
       " ('reciprocal', 'Debra Perlingiere : Kevin Ruscitti'),\n",
       " ('reciprocal', 'Drew Fossum : Susan Scott'),\n",
       " ('reciprocal', 'Elizabeth Sager : Janette Elbertson'),\n",
       " ('reciprocal', 'Elizabeth Sager : Mark Haedicke'),\n",
       " ('reciprocal', 'Elizabeth Sager : Mark Taylor'),\n",
       " ('reciprocal', 'Elizabeth Sager : Richard Sanders'),\n",
       " ('reciprocal', 'Eric Bass : Susan Scott'),\n",
       " ('reciprocal', 'Fletcher Sturm : Greg Whalley'),\n",
       " ('reciprocal', 'Fletcher Sturm : Sally Beck'),\n",
       " ('reciprocal', 'Gerald Nemec : Susan Scott'),\n",
       " ('reciprocal', 'Grant Masson : Vince Kaminski'),\n",
       " ('reciprocal', 'Greg Whalley : Richard Sanders'),\n",
       " ('reciprocal', 'Janette Elbertson : Mark Taylor'),\n",
       " ('reciprocal', 'Janette Elbertson : Richard Sanders'),\n",
       " ('reciprocal', 'Liz Taylor : Mark Haedicke'),\n",
       " ('reciprocal', 'Mark Haedicke : Mark Taylor'),\n",
       " ('reciprocal', 'Mark Haedicke : Michelle Cash'),\n",
       " ('reciprocal', 'Mark Haedicke : Richard Sanders'),\n",
       " ('reciprocal', 'Mark Haedicke : Twanda Sweet'),\n",
       " ('reciprocal', 'Mark Taylor : Sara Shackleton'),\n",
       " ('reciprocal', 'Mark Taylor : Tana Jones'),\n",
       " ('reciprocal', 'Michelle Cash : Twanda Sweet'),\n",
       " ('reciprocal', 'Pinnamaneni Krishnarao : Vince Kaminski'),\n",
       " ('reciprocal', 'Richard Sanders : Sara Shackleton'),\n",
       " ('reciprocal', 'Rosalee Fleming : Steven Kean'),\n",
       " ('reciprocal', 'Sara Shackleton : Tana Jones'),\n",
       " ('reciprocal', 'Shirley Crenshaw : Vince Kaminski'),\n",
       " ('reciprocal', 'Stinson Gibner : Vince Kaminski'),\n",
       " ('reciprocal', 'Vasant Shanbhogue : Vince Kaminski')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get a list of all the reciprocal relationships\n",
    "\n",
    "Steps: \n",
    "1) Get all the from-to pairs, sort them and give each pair a 1 (k3 - v3: from-to - 1)\n",
    "2) Reduce all the k3 - v3 pairs by the keys (k4 - v4: from-to - sum of v3)\n",
    "3) Only take any k4 - v4 pairs where v4 > 1 (k5 - v5: from-to - sum of v4>1)\n",
    "4) Format the result using map (k6 - v6: 'reciprocal' - name1 : name2)\n",
    "5) Collect\n",
    "\"\"\"\n",
    "sorted(enronNames.distinct() \\\n",
    "    .map(lambda x: (tuple(sorted(x)), 1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .filter(lambda x: x[1] > 1) \\\n",
    "    .map(lambda x: ('reciprocal', str(x[0][0]) + ' : ' + str(x[0][1]))) \\\n",
    "    .collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYC SAT performance\n",
    "\n",
    "The objective for this assignment was to find out if math scores vary across bus or subway lines. To do this, I used two NYC open data sets: the SAT Results and the NYC High School Directory data sets. Both can be downloaded from the links below:\n",
    "\n",
    "**SAT_Results.csv**\n",
    "Source: https://nycopendata.socrata.com/Education/SAT-Results/f9bf-2cp4  \n",
    "Description: “The most recent school level results for New York City on the SAT. Results are available at the school level for the graduating seniors of 2012.”\n",
    "\n",
    "**DOE_High_School_Directory_2014-2015.csv**\n",
    "Source: https://data.cityofnewyork.us/Education/DOE-High-School-Directory-2014-2015/n3p6-zve2  \n",
    "Description: “Directory of NYC High Schools.”\n",
    "\n",
    "The results are two lists:\n",
    "1. A list of key/value pairs: with bus lines as keys and the average math scores as values.\n",
    "2. A list of key/value pairs: with subway lines as keys and the average math scores as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store variables for the SAT results and school info\n",
    "SAT_FN = 'data/SAT_Results.csv'\n",
    "HSD_FN = 'data/DOE_High_School_Directory_2014-2015.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD of the SAT results\n",
    "sat = sc.textFile(SAT_FN, use_unicode=True).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('02M047', (400, 16)),\n",
       " ('21K410', (437, 475)),\n",
       " ('30Q301', (440, 98)),\n",
       " ('17K382', (374, 59)),\n",
       " ('18K637', (381, 35))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the DBNs, average math SAT scores, and number of test takers for all schools\n",
    "def extractScore(partitionId, rows):\n",
    "    # Skip the first row\n",
    "    if partitionId==0:\n",
    "        next(rows)\n",
    "    import csv\n",
    "    # Read in the data\n",
    "    reader = csv.reader(rows)\n",
    "    for fields in reader:\n",
    "        # Skip rows where number of test takers has 's'\n",
    "        if fields[2]!='s':\n",
    "            # Yield the DBN, average math SAT score, and number of test takers\n",
    "            yield (fields[0], (int(fields[4]), int(fields[2])))\n",
    "    \n",
    "satScores = sat.mapPartitionsWithIndex(extractScore)\n",
    "satScores.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat an RDD from the schools data\n",
    "schools = sc.textFile(HSD_FN, use_unicode=True).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M292', 'B39'),\n",
       " ('01M292', 'M14A'),\n",
       " ('01M292', 'M14D'),\n",
       " ('01M292', 'M15'),\n",
       " ('01M292', 'M15-SBS')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this code block: Extract the bus lines that access every school by DBN.\n",
    "\n",
    "I use a split to separate each bus line so that my k2 - v2 is: DBN - individual bus line.\n",
    "\"\"\"\n",
    "def extractBusGrades(partitionId, rows):\n",
    "    # Skip first row\n",
    "    if partitionId==0:\n",
    "        next(rows)\n",
    "    import csv\n",
    "    # Read in data\n",
    "    reader = csv.reader(rows)\n",
    "    for fields in reader:\n",
    "        # Make sure all columns are present\n",
    "        if len(fields)==58:\n",
    "            # Split the buslines\n",
    "            for busline in fields[10].strip().split(','):\n",
    "                # Yield the DBN and busline\n",
    "                yield (fields[0], busline.strip())\n",
    "    \n",
    "busGrades = schools.mapPartitionsWithIndex(extractBusGrades)\n",
    "busGrades.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M292', 'B'),\n",
       " ('01M292', 'D'),\n",
       " ('01M292', 'F'),\n",
       " ('01M292', 'J'),\n",
       " ('01M292', 'M')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Purpose of this code block: Extract the subway lines that access every school by DBN.\n",
    "\n",
    "I use a series of splits in order to separate out every subway line, remove station names, and then yield each school \n",
    "as a DBN with each subway line that has access to that school (k2 - v2: DBN - individual subway line).\n",
    "\"\"\"\n",
    "def extractSubwayGrades(partitionId, rows):\n",
    "    # Skip first row\n",
    "    if partitionId==0:\n",
    "        next(rows)\n",
    "    import csv\n",
    "    # Read in data\n",
    "    reader = csv.reader(rows)\n",
    "    for fields in reader:\n",
    "        # Check to make sure all columns are present\n",
    "        if len(fields)==58:\n",
    "            # First split for each subway line\n",
    "            for subline_station in fields[11].split(';'):\n",
    "                # Split the lines and the related stations\n",
    "                for sublines in subline_station.split(' to'):\n",
    "                    # Split each individual subway line\n",
    "                    for line in sublines.strip().split(','):\n",
    "                        # Only take the subway lines and not the stations\n",
    "                        if len(line.strip()) == 1:\n",
    "                            yield (fields[0], line.strip())\n",
    "\n",
    "subwayGrades = schools.mapPartitionsWithIndex(extractSubwayGrades)\n",
    "subwayGrades.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S1115', 612),\n",
       " ('M79', 594),\n",
       " ('Q42', 582),\n",
       " ('M22', 574),\n",
       " ('Bx3', 571),\n",
       " ('B52', 560),\n",
       " ('B63', 557),\n",
       " ('B69', 548),\n",
       " ('B54', 543),\n",
       " ('B25', 541),\n",
       " ('M20', 540),\n",
       " ('M9', 539),\n",
       " ('M86', 538),\n",
       " ('B65', 538),\n",
       " ('B45', 534),\n",
       " ('Bx10', 534),\n",
       " ('Bx26', 533),\n",
       " ('B103', 531),\n",
       " ('Q64', 529),\n",
       " ('Bx22', 525),\n",
       " ('M72', 523),\n",
       " ('B41', 520),\n",
       " ('B38', 520),\n",
       " ('M5', 520),\n",
       " ('Q35', 519),\n",
       " ('M66', 518),\n",
       " ('B62', 513),\n",
       " ('Q88', 508),\n",
       " ('Q30', 507),\n",
       " ('Q84', 507),\n",
       " ('S79-SBS', 505),\n",
       " ('Q20A', 505),\n",
       " ('Q31', 504),\n",
       " ('B11', 503),\n",
       " ('M35', 496),\n",
       " ('Q17', 495),\n",
       " ('M10', 495),\n",
       " ('Q28', 492),\n",
       " ('Q13', 492),\n",
       " ('S57', 490),\n",
       " ('M31', 490),\n",
       " ('Bx28', 489),\n",
       " ('B9', 489),\n",
       " ('Q76', 488),\n",
       " ('S74', 486),\n",
       " ('S76', 486),\n",
       " ('S78', 486),\n",
       " ('S55', 486),\n",
       " ('M57', 485),\n",
       " ('M21', 485),\n",
       " ('Q85', 485),\n",
       " ('B8', 485),\n",
       " ('M7', 483),\n",
       " ('Q23', 482),\n",
       " ('Q20B', 481),\n",
       " ('Q27', 481),\n",
       " ('Q60', 479),\n",
       " ('Q4', 479),\n",
       " ('M104', 477),\n",
       " ('M11', 477),\n",
       " ('B70', 476),\n",
       " ('S56', 476),\n",
       " ('M14A', 475),\n",
       " ('B100', 475),\n",
       " ('B31', 475),\n",
       " ('B2', 475),\n",
       " ('Q102', 474),\n",
       " ('S54', 474),\n",
       " ('S59', 473),\n",
       " ('Q25', 473),\n",
       " ('B49', 471),\n",
       " ('M106', 470),\n",
       " ('Bx2', 470),\n",
       " ('M14D', 468),\n",
       " ('B6', 467),\n",
       " ('M116', 467),\n",
       " ('M8', 467),\n",
       " ('Q32', 466),\n",
       " ('Q36', 466),\n",
       " ('Q67', 466),\n",
       " ('Q39', 466),\n",
       " ('B4', 466),\n",
       " ('B68', 465),\n",
       " ('B44-SBS', 465),\n",
       " ('B44', 465),\n",
       " ('Q101', 464),\n",
       " ('Bx1', 464),\n",
       " ('Q65', 464),\n",
       " ('M23', 462),\n",
       " ('Q9', 462),\n",
       " ('Q110', 462),\n",
       " ('Q66', 461),\n",
       " ('B1', 461),\n",
       " ('M15', 459),\n",
       " ('Q38', 456),\n",
       " ('Q5', 456),\n",
       " ('Q3', 456),\n",
       " ('M102', 455),\n",
       " ('Bx20', 455),\n",
       " ('B64', 454),\n",
       " ('Q100', 454),\n",
       " ('M101', 453),\n",
       " ('Q104', 452),\n",
       " ('M15-SBS', 452),\n",
       " ('S53', 452),\n",
       " ('S61', 451),\n",
       " ('Q46', 451),\n",
       " ('M2', 449),\n",
       " ('Q83', 449),\n",
       " ('B16', 448),\n",
       " ('Q6', 446),\n",
       " ('Q111', 446),\n",
       " ('Q16', 445),\n",
       " ('Q69', 444),\n",
       " ('Q103', 443),\n",
       " ('Q8', 443),\n",
       " ('S66', 442),\n",
       " ('M4', 442),\n",
       " ('Q112', 441),\n",
       " ('M103', 441),\n",
       " ('Q34', 441),\n",
       " ('Q48', 441),\n",
       " ('B82', 440),\n",
       " ('Q41', 440),\n",
       " ('M50', 438),\n",
       " ('B39', 438),\n",
       " ('Q113', 438),\n",
       " ('S89', 438),\n",
       " ('Q15A', 438),\n",
       " ('Q26', 438),\n",
       " ('Q12', 438),\n",
       " ('Q15', 438),\n",
       " ('Q53', 437),\n",
       " ('M34A-SBS', 437),\n",
       " ('S44', 435),\n",
       " ('Q22', 435),\n",
       " ('Q18', 434),\n",
       " ('S40', 434),\n",
       " ('S46', 434),\n",
       " ('Q11', 434),\n",
       " ('Q24', 434),\n",
       " ('Q56', 434),\n",
       " ('Q43', 432),\n",
       " ('B36', 432),\n",
       " ('M3', 432),\n",
       " ('S48', 432),\n",
       " ('S42', 432),\n",
       " ('S52', 432),\n",
       " ('S62', 432),\n",
       " ('B24', 432),\n",
       " ('B84', 432),\n",
       " ('Bx24', 430),\n",
       " ('M100', 427),\n",
       " ('Bx33', 426),\n",
       " ('Q29', 423),\n",
       " ('Q72', 423),\n",
       " ('N/A', 423),\n",
       " ('Q37', 422),\n",
       " ('S51', 422),\n",
       " ('B67', 420),\n",
       " ('Q2', 419),\n",
       " ('Q59', 418),\n",
       " ('M34-SBS', 417),\n",
       " ('Bx31', 417),\n",
       " ('Q40', 417),\n",
       " ('Bx34', 416),\n",
       " ('M1', 413),\n",
       " ('Bx19', 413),\n",
       " ('Q77', 413),\n",
       " ('Q1', 412),\n",
       " ('B48', 412),\n",
       " ('B43', 411),\n",
       " ('M42', 410),\n",
       " ('Q58', 410),\n",
       " ('M98', 409),\n",
       " ('Bx8', 409),\n",
       " ('B32', 409),\n",
       " ('Q54', 408),\n",
       " ('Q7', 407),\n",
       " ('B57', 405),\n",
       " ('Bx12-SBS', 405),\n",
       " ('Bx12', 405),\n",
       " ('Q10', 404),\n",
       " ('Bx7', 402),\n",
       " ('M96', 401),\n",
       " ('Bx30', 401),\n",
       " ('Bx40', 400),\n",
       " ('Bx42', 400),\n",
       " ('B61', 400),\n",
       " ('Bx21', 398),\n",
       " ('Bx13', 398),\n",
       " ('B60', 398),\n",
       " ('Bx32', 397),\n",
       " ('B13', 397),\n",
       " ('Bx6', 396),\n",
       " ('Bx39', 395),\n",
       " ('Q55', 394),\n",
       " ('Bx15', 393),\n",
       " ('Bx23', 392),\n",
       " ('Bx29', 392),\n",
       " ('Q50', 392),\n",
       " ('Bx4', 391),\n",
       " ('Bx4A', 391),\n",
       " ('B12', 390),\n",
       " ('B14', 390),\n",
       " ('B46', 390),\n",
       " ('B35', 390),\n",
       " ('Bx35', 389),\n",
       " ('Bx11', 389),\n",
       " ('B26', 389),\n",
       " ('Bx41-SBS', 389),\n",
       " ('Bx9', 389),\n",
       " ('Bx17', 389),\n",
       " ('Bx41', 388),\n",
       " ('B17', 385),\n",
       " ('B42', 384),\n",
       " ('B15', 382),\n",
       " ('B3', 382),\n",
       " ('Bx18', 382),\n",
       " ('Bx5', 382),\n",
       " ('Bx38', 378),\n",
       " ('B7', 378),\n",
       " ('Bx46', 376),\n",
       " ('B83', 376),\n",
       " ('B47', 374),\n",
       " ('Bx36', 372),\n",
       " ('B20', 372),\n",
       " ('Bx27', 371),\n",
       " ('M60', 357),\n",
       " ('Q44', 354)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grades for bus lines only and sort by average math SAT score in descending order\n",
    "\n",
    "Step-by-step: \n",
    "1) Union all bus info for schools and join with SAT scores (k3 - v3: DBN - (bus, (avg math SAT score, # of test takers))\n",
    "2) Get the total average SAT score by multiplying the average SAT score for each line by the number of test takers (k4\n",
    " - v4: bus line - (total average math SAT score, number of test takers))\n",
    "3) Reduce by the bus line as a key (k5 - v5: bus line - (total average math SAT score, total number of test takers))\n",
    "4) Divide by the total number of test takers for each line to get the average for each line (k6 - v6: bus line - \n",
    "average math SAT score)\n",
    "5) Switch the keys and values using map (k7 - v7: average math SAT score - bus line)\n",
    "6) Sort by the keys aka average math SAT scores (k8 - v8: sorted average math SAT score - bus line)\n",
    "7) Switch the keys and values again to get the proper key - value format (k9 - v9: bus line - sorted and rounded \n",
    "average math SAT score)\n",
    "\"\"\"\n",
    "busGrades.join(satScores) \\\n",
    "    .values() \\\n",
    "    .mapValues(lambda x: (x[0]*x[1], x[1])) \\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "    .mapValues(lambda x: x[0]/x[1]) \\\n",
    "    .map(lambda x: (x[1], x[0])) \\\n",
    "    .sortByKey(ascending=False) \\\n",
    "    .map(lambda x: (x[1], int(x[0]))) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 513),\n",
       " ('C', 510),\n",
       " ('A', 510),\n",
       " ('R', 508),\n",
       " ('G', 503),\n",
       " ('D', 502),\n",
       " ('E', 501),\n",
       " ('1', 499),\n",
       " ('4', 495),\n",
       " ('N', 493),\n",
       " ('B', 491),\n",
       " ('2', 488),\n",
       " ('Q', 482),\n",
       " ('5', 461),\n",
       " ('7', 457),\n",
       " ('M', 454),\n",
       " ('F', 445),\n",
       " ('J', 439),\n",
       " ('Z', 438),\n",
       " ('6', 432),\n",
       " ('S', 427),\n",
       " ('L', 426)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grades for subway lines only and sort by average math SAT score in descending order\n",
    "\n",
    "Step-by-step: \n",
    "1) Union all subway info for schools and join with SAT scores (k3 - v3: DBN - (subway, (avg math SAT score, # of test \n",
    "takers))\n",
    "2) Get the total average SAT score by multiplying the average SAT score for each line by the number of test takers (k4\n",
    " - v4: subway line - (total average math SAT score, number of test takers))\n",
    "3) Reduce by the subway line as a key (k5 - v5: subway line - (total average math SAT score, total number of test \n",
    "takers))\n",
    "4) Divide by the total number of test takers for each line to get the average for each line (k6 - v6: subway line - \n",
    "average math SAT score)\n",
    "5) Switch the keys and values using map (k7 - v7: average math SAT score - subway line)\n",
    "6) Sort by the keys aka average math SAT scores (k8 - v8: sorted average math SAT score - subway line)\n",
    "7) Switch the keys and values again to get the proper key - value format (k9 - v9: subway line - sorted and rounded \n",
    "average math SAT score)\n",
    "\"\"\"\n",
    "subwayGrades.join(satScores) \\\n",
    "    .values() \\\n",
    "    .mapValues(lambda x: (x[0]*x[1], x[1])) \\\n",
    "    .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "    .mapValues(lambda x: x[0]/x[1]) \\\n",
    "    .map(lambda x: (x[1], x[0])) \\\n",
    "    .sortByKey(ascending=False) \\\n",
    "    .map(lambda x: (x[1], int(x[0]))) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
